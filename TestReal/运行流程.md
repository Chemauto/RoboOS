# 实时视觉导航 Demo 运行流程 (Local 模式) - 最终稳定版

本 Demo 演示 RoboOS 如何通过大模型控制**本地模拟机器人**，实现“视觉导航”任务。
所有修改和新增文件均在 `TestReal` 目录下，其核心逻辑、端口和通信方式已与原始项目**完全同步并保持一致**。

## 1. 核心文件路径

所有操作均在 `/home/dora/RoboOs/RoboOS/TestReal` 目录下进行。

## 2. **停止所有现有 RoboOS 相关进程！**

在启动新进程之前，请务必确保所有可能占用 **5000 端口 (Master)** 和 **8888 端口 (Deploy)** 的旧 RoboOS 进程（包括 `master_run.py`, `slaver_run.py`, `deploy_run.py`）都已完全终止。您可以使用以下命令查找并终止它们：

```bash
sudo lsof -t -i:5000 | xargs -r sudo kill -9
sudo lsof -t -i:8888 | xargs -r sudo kill -9
```

## 3. **启动 VLLM 大模型 API 服务器**

请确保您的大模型 VLLM API 服务器正在运行，并且监听在 `0.0.0.0:4567`。例如：

```bash
python -m vllm.entrypoints.openai.api_server \
  --model /home/dora/RoboBrain2.0/Model_3B \
  --host 0.0.0.0 \
  --port 4567 \
  --served-model-name robobrain \
  --gpu-memory-utilization 0.90 \
  --max-model-len 10000 \
  --max-num-seqs 256 \
  --trust-remote-code \
  --enable-chunked-prefill \
  --enable-auto-tool-choice \
  --tool-call-parser hermes \
  --chat-template /home/dora/RoboOs/RoboOS/deploy/templates/tool_chat_template_hermes.jinja
```

## 4. 启动顺序 (需 3 个终端)

### 终端 1: **Master 服务**

在 `/home/dora/RoboOs/RoboOS/TestReal` 目录下运行：
```bash
python master_run.py
```
**预期输出**: Master 启动，监听 **5000** 端口，并且日志显示成功连接到 Redis 和初始化 `NewGlobalAgent`。

### 终端 2: **Slaver 服务**

在 `/home/dora/RoboOs/RoboOS/TestReal` 目录下运行：
```bash
python slaver_run.py
```
**预期输出**: Slaver 启动，加载 `TestReal/config.yaml`，在后台启动 `skill.py` 子进程，并向 Master (端口 5000) 注册 `find_object` 和 `navigate_to_target` 技能。

### 终端 3: **Deploy UI 界面**

在 `/home/dora/RoboOs/RoboOS/TestReal` 目录下运行：
```bash
python deploy_run.py
```
**预期输出**: Deploy 服务启动，监听 **8888** 端口。

## 5. 访问和操作

-   在浏览器中打开：`http://127.0.0.1:8888/release`。
-   点击页面上的 **"Test Connection"** 按钮。您应该会看到连接状态变为 **"Connected"**。
-   在页面右侧的 **"Robot status"** 区域，应该会显示一个名为 `demo_robot` 的机器人，状态为 **"idle"**。
-   在页面的消息输入框中下达指令，例如:
    `"find the water bottle and go to it"`

## 6. 预期结果

-   **Master (终端 1)**: 日志会显示接收到任务，并与 LLM 交互进行任务规划。如果 LLM 响应正常，任务将被分解，并通过 Redis 转发给 Slaver。
-   **Slaver (终端 2)**: 收到子任务 -> 内部 LLM 决策 -> 调用**本地子进程 `skill.py`** 中的 `find_object` 和 `navigate_to_target` 方法 -> 收到坐标 -> 调用 `navigate_to_target` -> 收到“导航完成” -> 向 Master 报告任务完成。
-   **Slaver (终端 2)**: 会打印出来自 `skill.py` 的日志，显示模拟的物体寻找和机器人移动。
-   **Deploy UI (浏览器)**: 实时显示任务状态和结果，任务步骤会逐步更新。
