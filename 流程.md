# RoboOS 端到端工作流程详解

本文档旨在详细拆解当用户输入一句自然语言指令后，RoboOS系统内部发生的完整工作流程。我们将以用户输入 `“先去厨房，然后向前移动1米”` 为例，追踪数据在系统中的每一步流转。

### 核心组件概览

-   **Master Agent (大脑)**: 负责理解用户意图、进行全局任务规划与分解。
-   **Slaver Agent (小脑)**: 负责接收并执行具体的子任务，将任务转化为对机器人技能的精确调用。
-   **LLM (大语言模型)**: 作为“外脑”，同时为Master和Slaver提供推理能力。
-   **Redis (协作器)**: 作为通信中枢和共享记忆中心，连接大脑和小脑。
-   **Skill Library (`skill.py`)**: 机器人的具体能力实现，是动作的最终执行者。

---

### 流程图概览

```
用户指令 -> [Master Agent] -> [LLM进行任务规划] -> [Redis消息队列] -> [Slaver Agent] -> [LLM进行工具选择] -> [Skill.py 执行] -> [返回结果]
```

---

## 阶段一：系统初始化与技能注册 (准备阶段)

在用户下达任何指令之前，系统需要先完成准备工作。

1.  **Slaver启动**:
    -   `slaver/run.py` 被执行。
    -   Slaver通过MCP协议启动并加载 `slaver/demo_robot_local/skill.py` 文件。
    -   它会**解析`skill.py`中所有被`@mcp.tool()`装饰的函数**，提取出每个技能的详细信息，包括：
        -   函数名 (`name`): `navigate_to_target`, `move`
        -   函数描述 (`description`): "Navigate to a predefined target location..."
        -   输入参数 (`inputSchema`): `{"target": "string"}`, `{"direction": "float", ...}`
    -   这个包含所有技能信息的列表被称为 `tools`。

2.  **技能上报与注册**:
    -   Slaver将自己的名称 (`demo_robot`) 和解析出的`tools`列表打包成一个JSON对象。
    -   通过`FlagScale`库中的`Collaborator`，Slaver将这个包含自身和技能信息的JSON对象**注册到Redis数据库中**。
    -   至此，Slaver进入待命状态，并开始通过Redis订阅专门发送给它的指令频道（例如`roboos_to_demo_robot`）。

3.  **Master启动**:
    -   `master/run.py` 被执行。
    -   Master Agent启动，并通过`Collaborator`连接到同一个Redis数据库。
    -   它会监听服务注册信息，此时它能从Redis中发现`demo_robot`已经在线，并且**准确地知道`demo_robot`拥有`navigate_to_target`和`move`这两个技能及其详细用法**。

---

## 阶段二：任务下达与Master的全局规划 (大脑思考)

现在，用户通过`test_navigation.py`脚本输入了指令：`“先去厨房，然后向前移动1米”`。

1.  **接收任务**:
    -   `test_navigation.py` 将任务通过HTTP POST请求发送到Master的Web服务接口 (`master/run.py`)。
    -   `GlobalAgent` (`master/agents/agent.py`) 接收到这个全局任务。

2.  **构建LLM的思考上下文**:
    -   `GlobalAgent`调用`GlobalTaskPlanner` (`master/agents/planner.py`) 来处理这个任务。
    -   `GlobalTaskPlanner`开始**收集规划所需的所有信息**：
        a.  **用户任务**: `“先去厨房，然后向前移动1米”`
        b.  **机器人及其技能**: 从Redis中读取到 `demo_robot` 及其拥有的 `navigate_to_target` 和 `move` 技能的详细描述。
        c.  **场景信息**: 从 `master/scene/profile.yaml` 加载的环境信息（厨房桌子、垃圾桶等）。

3.  **生成并发送Prompt**:
    -   `GlobalTaskPlanner`使用`master/agents/prompts.py`中的`MASTER_PLANNING_PLANNING`模板，将上述所有信息**组合成一个巨大的、详细的Prompt**。这个Prompt的大意是：
      > “你是一个任务规划专家。现在有一个机器人`demo_robot`，它有以下技能：[...技能描述...]。场景里有这些东西：[...场景信息...]。请你将这个任务`“先去厨房，然后向前移动1米”`分解成一系列子任务，并以JSON格式返回你的思考过程和子任务列表。”

4.  **LLM进行任务分解**:
    -   这个Prompt被发送到在`master/config.yaml`中配置的大语言模型API。
    -   LLM根据详尽的上下文信息进行“思考”。它知道机器人有`navigate_to_target`技能可以用来完成“去厨房”的意图，也有`move`技能可以用来完成“向前移动1米”的意图。
    -   LLM返回一个JSON结果，如下所示：
      ```json
      {
        "reasoning_explanation": "首先，用户要求机器人去厨房，这可以直接使用navigate_to_target技能实现。然后，用户要求向前移动1米，这可以通过move技能实现，其中方向是0度（代表正前方），速度和时间可以估算，例如速度1米/秒，时间1秒。",
        "subtask_list": [
          {
            "robot_name": "demo_robot",
            "subtask": "navigate to the kitchen",
            "subtask_order": 1
          },
          {
            "robot_name": "demo_robot",
            "subtask": "move forward for 1 meter",
            "subtask_order": 2
          }
        ]
      }
      ```

---

## 阶段三：子任务分发与Slaver的精确执行 (小脑执行)

1.  **分发子任务**:
    -   `GlobalAgent`接收到LLM返回的JSON，并解析出`subtask_list`。
    -   它发现这是一个串行任务（`subtask_order`不同），于是先取出第一个子任务：`"navigate to the kitchen"`。
    -   `GlobalAgent`通过Redis的`roboos_to_demo_robot`频道，将这个子任务**发布**出去。

2.  **Slaver接收并处理子任务**:
    -   正在监听此频道的`Slaver` Agent (`slaver/run.py`) 立即收到了这个子任务。
    -   Slaver的`handle_task`方法被触发。它创建了一个`ToolCallingAgent`实例。

3.  **Slaver的LLM进行工具选择**:
    -   **这一步很关键**：Slaver**也会调用一次LLM**，但目的不同。Master的LLM调用是为了**任务规划**，而Slaver的LLM调用是为了**工具选择和参数提取**。
    -   `ToolCallingAgent`会构建一个更简单的Prompt，大意是：
      > “你有以下工具：[...技能描述...]。现在的任务是`"navigate to the kitchen"`。请选择最合适的工具并提取参数，以JSON格式返回。”
    -   LLM分析后，返回一个精确的工具调用JSON：
      ```json
      {"name": "navigate_to_target", "arguments": {"target": "kitchen"}}
      ```

4.  **调用并执行技能**:
    -   `ToolCallingAgent`解析这个JSON。
    -   它通过MCP客户端，向`skill.py`服务发起一个远程过程调用（RPC）：调用函数`navigate_to_target`，并传入参数`target='kitchen'`。
    -   `slaver/demo_robot_local/skill.py`中的`navigate_to_target`函数**最终被执行**。
    -   `print("Navigation to kitchen has been successfully performed.")` 这行代码被执行，您会在Slaver的终端（或日志文件）中看到这条消息。

---

## 阶段四：结果反馈与循环 (闭环)

1.  **返回结果**:
    -   `skill.py`中的函数执行完毕，返回结果（例如`"Navigation successful"`）。
    -   这个结果通过MCP返回给`Slaver` Agent。

2.  **上报状态**:
    -   `Slaver`将子任务的执行结果打包，通过Redis的另一个频道（例如`demo_robot_to_RoboOS`）**发送回Master**。
    -   `Slaver`同时更新自己在Redis中的状态为“空闲”。

3.  **执行下一个子任务**:
    -   `Master`接收到第一个子任务的成功回执，并且发现`demo_robot`已空闲。
    -   `Master`从任务列表中取出第二个子任务`"move forward for 1 meter"`，重复**阶段三**的流程，将其发送给Slaver。
    -   Slaver接收到新任务，再次调用LLM进行工具选择，LLM这次会返回：
      ```json
      {"name": "move", "arguments": {"direction": 0, "speed": 1.0, "duration": 1.0}}
      ```
    -   `skill.py`中的`move`函数被执行。

4.  **任务完成**:
    -   当所有子任务都成功执行并返回结果后，Master认为整个全局任务完成。

这个流程清晰地展示了Master如何进行宏观规划，以及Slaver如何进行微观执行，两者通过Redis和LLM的推理能力紧密协作，最终将一句模糊的人类语言指令，转化为机器人精确的物理动作。
